{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewer uihP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- W1: I am not quite sure about one of the key assumptions made in this paper: \"the non-causal substructure shares a similar pattern across graphs within a client but differs significantly among the clients\". Could you explain more why this assumption is valid? Or why it should be the case in real-world applications? To me, this is not clear.\n",
    "\n",
    "- R1: Thanks for bringing it up. We would like to clarify that the problem setting studied in this paper is derived from the graph out-of-distribution (OOD) problem. In graph OOD, multiple graphs are from different environments (i.e., domains). Graphs from the same environment are considered as drawn from an identical distribution. The labels of the graphs are determined by environment-invariant causal substructures, while the non-causal substructures are different across environments. This assumption is adopted by tremendous sutdies in graph OOD [4, 8, 16, 28 , 38, 39 , 47, 52 , 63]. **The problem setup of this study is simply transferred from traditional graph OOD to the federated setting by regarding each environment as a client and shares the same assumption as traditional graph OOD.** The only one extra constraint in FGL is that graphs from different clients/environments cannot be gathered. Besides Figure 1 in our paper, we provide a more practical scenario here. Considering a toy medical system with two institutes. Institute A studies benzene-based compounds so it mainly has molecules containing the phenyl group (e.g., benzoic acid molecules). In contrast, Institute B studies ester-based compounds so it mainly has molecules containing an ester (e.g., glyceride molecules). The goal of the two institutes is to jointly train a GNN model to predict the water solubility of molecules. Typically, the label (i.e., the water solubility) of each molecule is causally determined by the substructure hydroxy (i.e., -OH), which is invariant across the two institutes, while the function groups - the phenyl group in Institute A and the ester in Institute B - are non-causal substructures.\n",
    "\n",
    "---\n",
    "\n",
    "- W2: Besides the above point, the definition of causal substructure is also not clear. If we have the above assumption, how we can decide the causal/non-causal parts given any multiple graphs? And motivated by this assumption, how do we design the component accordingly? In my view, the edge generation only ensures the similarity within a\n",
    "\n",
    "- R2: Thanks for pointing out this concern. Like introduced in many existing studies [16, 39, 63], the causal substructure is a subgraph which invariantly determines a graph's label. We also illustrate this in the toy example with Figure 1. We would like to clarify that **our method does NOT decide which part in a graph is causal or non-causal**. The goal of our method is to augment graphs by properly injecting VNs into graphs so that we can obtain identical embeddings of graphs with different non-causal substructure across clients.\n",
    "\n",
    "---\n",
    "\n",
    "- W3: For VNs collapsing, in my view, it prevents VNs from having similar features. But could you explain why they cannot have similar features? In my view, they can still reside in different parts of the graphs, thus have different neighboring structures. Then, they can still contribute differently.\n",
    "\n",
    "- R3: Thanks for pointing it out. **We can understand the motivation of collapse prevention in both a) theoretical and b) intuitive ways.** a) First, if we hope to obtain a theoretically identical embedding of two different graphs $\\mathcal{G}$ and $\\mathcal{G}'$ shown in Theorem 1, one condition is that $Q$ must have full row rank, i.e., $rank(Q)=M$. It means that multiple VNs cannot collapse to fewer nodes (line 277). b) Second, considering the toy example in Figure 1, we intuitively hope to learn three VNs for Circle, Pentagon, and Square, respectively. If the three VNs collapse to one single node, it will be much harder to obtain identical desirable graphs like shown in Figure 1. Therefore, learning multiple VNs is the most straightforward and reasonable way in our design."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewer R1ZR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- W1: The proposed method seems to be a simple extension of existing graph data argumentation methods. There are multiple studies apply similar method like synthetic nodes (GraphMixup; CATSMOTE, Mathematics'22) or edge generation (GraphMOTE, WSDM'21).\n",
    "\n",
    "- R1: We would like to argue that **our graph augmentation-based method is fundamentally different from the mentioned methods with synthetic nodes and edge generation.** To better understand their differences, we compare them as follows.\n",
    "\n",
    "|                |   The mentioned studies   |        Our method      |\n",
    "|-----------------------|-----------------------------|-----------------------------|\n",
    "| Downstream task level |      Node level        |        Graph level     |\n",
    "| Problem setting     |     Centralized        |         Federated     |\n",
    "|   Challenge       |  Imbalanced node labels    | Distribution shifts in FGL  |\n",
    "|   Intuition of generated nodes       |  Increase the number of labeled nodes    | Modify graphs to mitigate the impact of non-causal substructures  |\n",
    "|  Way to obtain generated node features      | Interpolation/mixup of existing nodes    |  Directly learn features of virtual nodes   |\n",
    "| Way to obtain generated edges       |  Learn an edge generator by real edge reconstruction    |  Directly learn score vectors by personalized edge generators          |\n",
    "| Optimization loss                  |  Node classification loss + reconstruction loss     | Graph prediction loss + decoupling loss + score-contrastive loss |\n",
    "\n",
    "From the above table, we conclude that our method is completely different from the mentioned methods regarding every aforementioned point. \n",
    "\n",
    "---\n",
    "\n",
    "- W2: Theorem 1 seems to be incorrect. Theorem 1 says that, given a GNN and two graph inputs, with the virtual nodes added and a delicate selection of their edges, two graphs can produce the same node embeddings. However, in the proof, the missing condition for eq. 18 -> eq. 17 is that $M \\geq d_x$, i.e., the number of virtual nodes should be at least equal to the node embedding dimension. This is a very strong assumption and is missing in the manuscript. Also, in the experiments, the number of virtual nodes are chosen to be $\\leq 100$ but the node embedding dimension is 100.\n",
    "\n",
    "- R2: We would like to clarify that the only condition about $Q \\in \\mathbb{R}^{M\\times d_x}$ in Theorem 1 is that there exists a right inverse matrix of $Q$. This condition requires that $Q$ must have full row rank, i.e., $rank(Q)=M$. **It implies $M \\leq d_x$, NOT $M \\geq d_x$**. Therefore, we do not need to worry about the number of virtual nodes $M$. \n",
    "\n",
    "---\n",
    "\n",
    "- Q1: The edge generator also has a large amount of parameters. Why not average it in global epoch but instead keep it local?\n",
    "\n",
    "- A1: Thanks for bringing this up. We would like to emphasize that our method aims to perform client-specific graph augmentation for each client. Our method achieves this by letting each client determine how virtual nodes connect its local graphs in a personalized manner. In other words, the edge generator in a client only needs to be trained over the local graphs in the client. Therefore, the edge generator is kept locally in our method. In addition, personalized edge generators can avoid additional communication cost, which is a major concern in federated learning.\n",
    "\n",
    "---\n",
    "\n",
    "- Q2: As the proposed method aims to reduce the distribution shift among different clients, is there any demonstration on the graph data distribution before/after using the proposed methods?\n",
    "\n",
    "- A2: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewer ppoH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- W1: The related work about federated graph learning lacks of important works about the graph learning challenges in federated learning.\n",
    "\n",
    "- R1: \n",
    "\n",
    "---\n",
    "\n",
    "- W2: The distribution shift over clients is not clear. No clear definitions are presented to formulate this new graph challenge.\n",
    "\n",
    "- R2: \n",
    "\n",
    "---\n",
    "\n",
    "- W3: At the section 4.1, what is the graph data distribution P^k(G,y)? How to define P^k is not equal to P^j?\n",
    "\n",
    "- R3: \n",
    "\n",
    "---\n",
    "\n",
    "- W4: What is the causal substructure G_c? From the figure 1, G_c seems to be subgraph of each client graph.\n",
    "\n",
    "- R4: The causal substructure can be commonly regarded as a subgraph. In many studies [8, 52], substructures and subgraphs are interchangeably used.\n",
    "\n",
    "--- \n",
    "\n",
    "- W5: The definition of P^k(y) and P^k(G) is same or not.\n",
    "\n",
    "- R5: They are different. $P^{(k)}(y)$ is the label distribution in client $k$, while $P^{(k)}(\\mathcal{G})$ is the graph data distribution.\n",
    "\n",
    "---\n",
    "\n",
    "- W6: What about the graph property is presented? The goal of these clients is jointly train a GNN model f with parameters theta. How about the definition of the problem.\n",
    "\n",
    "- R6: \n",
    "\n",
    "--- \n",
    "\n",
    "- W7: In the section 4.2.2, more concretely, the clients will jointly learn M shared VNs with the feature matrix. The feature matrix is private, and how to jointly learn M shared VNs?\n",
    "\n",
    "- R7: We would like to emphasize that **the feature matrix of VNs is NOT private**. VNs are synthetic nodes whose features are directly learned as feature vectors.\n",
    "\n",
    "--- \n",
    "\n",
    "- W8: In the real clients, the graph shows heterogeneity challenge. The authors add few VNs in the client graphs, and the same desired graph is achieved. Thus one GNN model can be copied to each clients and trained. The problem is whether the VNs will introduce noise signals, and how to handle it?\n",
    "\n",
    "- R8: We believe that **VNs do NOT introduce noise signals**.\n",
    "\n",
    "---\n",
    "\n",
    "- L1: How to obtain the causal subgraph is not illustrated in detail. The causal structure impact on the federated graph learning task should be discussed in detail.\n",
    "\n",
    "- A1: We would like to clarify that **our method does NOT obtain the causal subgraph**. In addition, the diverse non-causal structures, NOT causal structures, impact the FGL task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewer FZdY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- W1: The paper focuses on graph-level property prediction in FGL and assumes different clients share the same label space and common causal substructures. The assumption is strong and limits the application of the proposed method in real applications that contain diverse graph data in different clients.\n",
    "\n",
    "- R1: Thanks for bringing it up. We would like to clarify that the problem setting studied in this paper is derived from the graph out-of-distribution (OOD) problem. In graph OOD, multiple graphs are from different environments (i.e., domains). Graphs from the same environment are considered as drawn from an identical distribution. The labels of the graphs are determined by environment-invariant causal substructures, while the non-causal substructures are different across environments. This assumption is adopted by tremendous sutdies in graph OOD [4, 8, 16, 28 , 38, 39 , 47, 52 , 63]. **The problem setup of this study is simply transferred from traditional graph OOD to the federated setting by regarding each environment as a client and shares the same assumption as traditional graph OOD.** The only one extra constraint in FGL is that graphs from different clients/environments cannot be gathered. Besides Figure 1 in our paper, we provide a more practical scenario here. Considering a toy medical system with two institutes. Institute A studies benzene-based compounds so it mainly has molecules containing the phenyl group (e.g., benzoic acid molecules). In contrast, Institute B studies ester-based compounds so it mainly has molecules containing an ester (e.g., glyceride molecules). The goal of the two institutes is to jointly train a GNN model to predict the water solubility of molecules. Typically, the label (i.e., the water solubility) of each molecule is causally determined by the substructure hydroxy (i.e., -OH), which is invariant across the two institutes, while the function groups - the phenyl group in Institute A and the ester in Institute B - are non-causal substructures.\n",
    "\n",
    "---\n",
    "- Q1: Can the proposed method be applied to the scenario where each client contains graphs from diverse domains?\n",
    "\n",
    "- A1: Thanks for pointing out this question. The proposed is compatible with clients having graph data from the same domain. We would like to argue that this setting is practical in real-world applications. Although two recent studies [40, 48] discussed FGL with cross-domain data (chemistry + social network), we believe the cross-domain scenario rarely happens in the real world. We will add the discussion in the revised version of our paper.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "- Q2: In the related work section, the authors should include more works on federated learning and contrastive learning in FL, to make this section more comprehensive.\n",
    "\n",
    "- A2: Thanks for your suggestion. We will add more related works in the revised version of our paper.\n",
    "\n",
    "---\n",
    "\n",
    "- Q3: In table 1, there are five settings. However, the caption says there are six settings.\n",
    "\n",
    "- A3: Thanks for pointing out this typo. We will correct this in our revised version once we can update our paper.\n",
    "\n",
    "---\n",
    "\n",
    "- Q4: For Eq (8), the definitions and calculations of $s_{local}$ and $s_{global}$ are not clear.\n",
    "\n",
    "- A4: Thanks for bringing up this point. As indicated in line 241, $\\textbf{s}_{local}$ is the average of $\\tilde{\\textbf{s}}_i^{(k)}$ in the current mini-batch. Specifically, given a mini-batch of graphs $\\{\\mathcal{G}_1^{(k)}, \\mathcal{G}_2^{(k)}, \\cdots, \\mathcal{G}_B^{(k)}\\}$ with their $\\{\\tilde{\\textbf{s}}_1^{(k)}, \\tilde{\\textbf{s}}_2^{(k)}, \\cdots, \\tilde{\\textbf{s}}_B^{(k)}\\}$ where $B$ is the batch size, $\\textbf{s}_{local}=\\frac{1}{B}\\sum_{i=1}^B \\tilde{\\textbf{s}}_i^{(k)}$. In the meantime, $\\textbf{s}_{global}$ is the global expected sum of score vectors. Empirically, we can use a positive constant vector (e.g., $\\mathbf{1}_M \\in \\mathbb{R}^M$) as $\\textbf{s}_{global}$. We will add the explanation in the revised version of our paper.\n",
    "\n",
    "---\n",
    "\n",
    "- Q5: The authors should further provide the time complexity introduced by the virtual nodes.\n",
    "\n",
    "- A5: \n",
    "\n",
    "---\n",
    "\n",
    "- Q6: The authors are encouraged to include discussions on graph explanation and graph out-of-distribution generalization as they share similar motivation with the paper i.e., focusing on the causal substructure of different graphs.\n",
    "\n",
    "- A6: Thanks for your suggestion. We would like to emphasize that we already included discussions on related studies about graph OOD generalization in Introduction (line 50-53). Although these studies attempt to grapple with the distribution shift of graph data from multiple sources for graph property prediction, these approaches are inapplicable to FGL since they require the multi-source graph data collected centrally in a mini-batch when training GNNs. This motivates us to propose our method in FGL. We will add related studies about  graph explanation in our revised version once we can update our paper.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewer CexK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Q1: how valid is the motivation of this paper (client-wise graph data heterogeneity).\n",
    "\n",
    "- A1: Besides Figure 1 in our paper, we would like to provide another motivated scenario here. Considering a toy medical system with two institutes. Institute A studies benzene-based compounds so it mainly has molecules containing the phenyl group (e.g., benzoic acid molecules). In contrast, Institute B studies ester-based compounds so it mainly has molecules containing an ester (e.g., glyceride molecules). The goal of the two institutes is to jointly train a GNN model to predict the water solubility of molecules. Typically, the label (i.e., the water solubility) of each molecule is causally determined by the substructure hydroxy (i.e., -OH), which is invariant across the two institutes, while the function groups - the phenyl group in Institute A and the ester in Institute B - are non-causal substructures. Another motivated scenario is the Motif dataset in our experiment, which is designed for graph out-of-distribution (OOD) problem. We adapt it for the federated setting in our experiment. Each graph in the Motif dataset is generated by connecting a motif (causal substructure) and a base graph (non-causal substructure), i.e., its label is solely determined by the motif. Graphs are generated using five label-irrelevant base graphs (wheel, tree, ladder, star, and path) and three label-related motifs (house, cycle, and crane). In traditional graph OOD, the Motif dataset has five environments by base graphs. In our experiment, we regard each environment as a client; therefore different clients have identical causal substructures with completely diverse non-causal substructures.\n",
    "\n",
    "---\n",
    "\n",
    "- Q2: how valid is the assumption of this paper (causal graph structures are common among clients, while non-causal graph structures are consistent client-wise but vary significantly among clients).\n",
    "\n",
    "- A2: - R1: Thanks for bringing it up. We would like to clarify that the problem setting studied in this paper is derived from the graph out-of-distribution (OOD) problem. In graph OOD, multiple graphs are from different environments (i.e., domains). Graphs from the same environment are considered as drawn from an identical distribution. The labels of the graphs are determined by environment-invariant causal substructures, while the non-causal substructures are different across environments. This assumption is adopted by tremendous sutdies in graph OOD [4, 8, 16, 28 , 38, 39 , 47, 52 , 63]. **The problem setup of this study is simply transferred from traditional graph OOD to the federated setting by regarding each environment as a client and shares the same assumption as traditional graph OOD.** The only one extra constraint in FGL is that graphs from different clients/environments cannot be gathered. \n",
    "\n",
    "---\n",
    "\n",
    "- Q3: how effective is FedVN in bridging the distributions across clients.\n",
    "\n",
    "- A3: \n",
    "\n",
    "--- \n",
    "\n",
    "- Q4: how does the loss in Eqn. 8 work on different client heterogeneity patterns.\n",
    "\n",
    "- A4: Thanks for pointing out this concern. We would like to clarify that **Eqn. 8 still works even when there exist some clients sharing similar underlying data generation processes.** We may consider a scenario where clients are highly clustered: clients 1, 2, $\\cdots, [\\frac{k}{2}]$ have the identical data distribution and have the similar VN connection pattern, e.g., $\\textbf{s}_{local}=[1, 0]$, while clients $[\\frac{k}{2}]+1, \\cdots, K$ have another identical data distribution and have the similar VN connection pattern, e.g., $\\textbf{s}_{local}'=[0, 1]$. Therefore, he global expected sum of score vectors $\\textbf{s}_{global}= \\frac{\\textbf{s}_{local} + \\textbf{s}_{local}'}{2} = [0.5, 0.5]$. For each client 1, 2, $\\cdots, [\\frac{k}{2}]$, Eqn. 8 will encourage $\\tilde{\\textbf{s}}$ to get closer to $\\textbf{s}_{local}=[1, 0]$ and further from $\\textbf{s}_{global} = [0.5, 0.5]$. Similarly for each client $[\\frac{k}{2}]+1, \\cdots, K$. This operation is consistent with our aim when designing Eqn. 8. As for clients are close to homogeneous, we believe that it might be beyond the scope of federated learning since data heterogeneity is one major concern in federated learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
